{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480344c7-8815-4d23-a631-79bd15d5d202",
   "metadata": {},
   "source": [
    "### Transpose Main Datasets (GSE120584 & GSE167559)\n",
    "\n",
    "**Description:**\n",
    "\n",
    "- **Load the Dataset:** Reads the dataset from a CSV file.\n",
    "- **Transpose the DataFrame:** Swaps rows and columns.\n",
    "- **Set Column Headers:** Uses the first row as the column headers.\n",
    "- **Drop Original Header Row:** Removes the row used for headers.\n",
    "- **Set Row Index Header:** Renames the row index to \"ID_1\".\n",
    "- **Save to CSV:** Optionally saves the transposed DataFrame to a new CSV file.\n",
    "- **Example Usage:** Applies the function to each file path provided, saving the transposed datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183f1103-7922-4010-97ad-c53e131d1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774bac3a-cae2-4cea-98c0-e6e43c6c1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_and_clean_dataset(file_path, output_file=None):\n",
    "    # Load the dataset\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    \n",
    "    # Transpose the DataFrame\n",
    "    dataset = dataset.T\n",
    "    \n",
    "    # Set the first row as column headers\n",
    "    dataset.columns = dataset.iloc[0]\n",
    "    \n",
    "    # Drop the original header row\n",
    "    dataset = dataset.drop(dataset.index[0])\n",
    "    \n",
    "    # Set the row index header to \"ID_1\"\n",
    "    dataset.index.rename(\"ID_1\", inplace=True)\n",
    "    \n",
    "    # Save to CSV if an output file path is provided\n",
    "    if output_file:\n",
    "        dataset.to_csv(output_file)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589dfd2b-84ab-49bf-9cbb-bd8ad4a2af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for the provided file paths\n",
    "file_paths = [\n",
    "    \"/home/aghasemi/CompBio481/datasets/original_datasets/GSE120584.csv\",\n",
    "    \"/home/aghasemi/CompBio481/datasets/original_datasets/GSE167559.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a10472e-f601-49e6-9625-78ebd07e6e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_REF     MIMAT0000062 MIMAT0000063 MIMAT0000064 MIMAT0000065 MIMAT0000066  \\\n",
      "ID_1                                                                          \n",
      "GSM3403761     2.307579     2.307579     2.307579     2.307579     2.307579   \n",
      "GSM3403762     1.503044      2.50538     1.503044     1.503044     1.503044   \n",
      "GSM3403763     1.549877     1.983125     1.549877     1.549877     1.549877   \n",
      "GSM3403764     1.560269     1.560269     1.560269     1.560269     2.232974   \n",
      "GSM3403765     3.179096     3.302472     3.179096     3.179096      4.79347   \n",
      "\n",
      "ID_REF     MIMAT0000067 MIMAT0000068 MIMAT0000069 MIMAT0000070 MIMAT0000071  \\\n",
      "ID_1                                                                          \n",
      "GSM3403761     2.307579     2.307579     2.307579     2.307579     2.843409   \n",
      "GSM3403762     1.503044     1.503044     1.503044     1.503044     3.349936   \n",
      "GSM3403763     1.549877     1.549877     1.549877     1.549877     3.081569   \n",
      "GSM3403764     1.560269     1.560269     1.560269     1.560269     1.890881   \n",
      "GSM3403765     3.179096     3.179096     3.179096     3.179096     3.650599   \n",
      "\n",
      "ID_REF      ... MIMAT0031893 MIMAT0032026 MIMAT0032029 MIMAT0032110  \\\n",
      "ID_1        ...                                                       \n",
      "GSM3403761  ...     2.307579     2.307579     8.224806     2.307579   \n",
      "GSM3403762  ...     1.503044     1.503044     7.921326     2.339842   \n",
      "GSM3403763  ...     1.549877     1.549877     7.659609     2.939463   \n",
      "GSM3403764  ...     1.560269     1.560269     7.145303     3.039567   \n",
      "GSM3403765  ...     3.179096     3.179096     8.254947     3.179096   \n",
      "\n",
      "ID_REF     MIMAT0032114, MIMAT0032115 MIMAT0032116 MIMAT0033692 MIMAT0035542  \\\n",
      "ID_1                                                                           \n",
      "GSM3403761                   2.307579      4.83835       5.0081     4.013143   \n",
      "GSM3403762                   1.503044     4.921429     5.103016     4.232799   \n",
      "GSM3403763                   1.549877     5.448523     4.882961     3.991961   \n",
      "GSM3403764                   1.560269     4.421061     4.522823     3.199755   \n",
      "GSM3403765                   3.179096     4.437597     4.536771     3.730172   \n",
      "\n",
      "ID_REF     MIMAT0035703 MIMAT0035704  \n",
      "ID_1                                  \n",
      "GSM3403761     2.307579     2.307579  \n",
      "GSM3403762     1.503044     1.503044  \n",
      "GSM3403763     1.549877     1.549877  \n",
      "GSM3403764     1.560269     1.560269  \n",
      "GSM3403765     3.179096     3.179096  \n",
      "\n",
      "[5 rows x 2562 columns]\n",
      "ID_REF     MIMAT0000062 MIMAT0000063 MIMAT0000064 MIMAT0000065 MIMAT0000066  \\\n",
      "ID_1                                                                          \n",
      "GSM5107459      2.51662      2.51662      2.51662      2.51662      2.51662   \n",
      "GSM5107460     3.248416     3.248416     3.248416     3.248416     3.248416   \n",
      "GSM5107461     2.612083      4.88638     2.612083     2.612083     2.612083   \n",
      "GSM5107462     2.008433     2.008433     2.008433     2.008433     2.008433   \n",
      "GSM5107463     2.616826     2.616826     2.616826     2.616826     3.865346   \n",
      "\n",
      "ID_REF     MIMAT0000067 MIMAT0000068 MIMAT0000069 MIMAT0000070 MIMAT0000071  \\\n",
      "ID_1                                                                          \n",
      "GSM5107459      2.51662      2.51662      2.51662      2.51662     4.698512   \n",
      "GSM5107460     3.248416     3.248416     3.248416     3.248416     5.474644   \n",
      "GSM5107461     2.612083     2.790576     2.612083     2.612083      4.07674   \n",
      "GSM5107462     2.008433     2.008433     2.008433     2.008433     2.008433   \n",
      "GSM5107463     9.013609     2.616826     2.616826     3.118115     4.963741   \n",
      "\n",
      "ID_REF      ... MIMAT0031893 MIMAT0032026 MIMAT0032029 MIMAT0032110  \\\n",
      "ID_1        ...                                                       \n",
      "GSM5107459  ...     3.107842      2.51662     7.185442      2.51662   \n",
      "GSM5107460  ...     3.248416     3.248416     7.997272     3.248416   \n",
      "GSM5107461  ...     2.612083     2.612083     8.333578     2.612083   \n",
      "GSM5107462  ...     2.008433     2.008433     8.336593     2.594865   \n",
      "GSM5107463  ...     2.616826     4.407149     7.819856     2.616826   \n",
      "\n",
      "ID_REF     MIMAT0032114, MIMAT0032115 MIMAT0032116 MIMAT0033692 MIMAT0035542  \\\n",
      "ID_1                                                                           \n",
      "GSM5107459                   2.899204      4.85376     4.221382      2.51662   \n",
      "GSM5107460                   3.248416     4.587862     5.712409      4.26074   \n",
      "GSM5107461                   2.612083     5.258817     4.453784     3.013223   \n",
      "GSM5107462                   2.008433     5.753774     5.357458     2.008433   \n",
      "GSM5107463                   2.616826     6.808297     4.915189     4.078926   \n",
      "\n",
      "ID_REF     MIMAT0035703 MIMAT0035704  \n",
      "ID_1                                  \n",
      "GSM5107459      2.51662      2.51662  \n",
      "GSM5107460     3.248416     3.248416  \n",
      "GSM5107461     3.224983     2.612083  \n",
      "GSM5107462     2.008433     2.008433  \n",
      "GSM5107463     3.065123     2.616826  \n",
      "\n",
      "[5 rows x 2562 columns]\n"
     ]
    }
   ],
   "source": [
    "# You can iterate over the file paths to apply the function to each file\n",
    "for file_path in file_paths:\n",
    "    output_file = file_path.replace(\".csv\", \"_T.csv\")  # Naming the output file based on the input file\n",
    "    transposed_dataset = transpose_and_clean_dataset(file_path, output_file)\n",
    "    print(transposed_dataset.head())  # Display the first few rows of the transformed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabcac5-c17f-4001-b703-79aa724ae421",
   "metadata": {},
   "source": [
    "### Merge Main Datasets (GSE120584_T & GSE167559_T)\n",
    "\n",
    "**Description:**\n",
    "\n",
    "- **Load the Datasets:** Reads two datasets from CSV files.\n",
    "- **Concatenate DataFrames:** Combines the datasets row-wise.\n",
    "- **Rename Column:** Renames the first unnamed column to 'ID_1', if applicable.\n",
    "- **Save to CSV:** Optionally saves the combined DataFrame to a new CSV file.\n",
    "- **Example Usage:** Applies the function to merge the specified datasets and saves the combined result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af63fbd4-fa17-4894-ba4d-019edb31e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e33022-7f43-46cf-958a-a660f653191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_datasets(file_path_1, file_path_2, output_file=None):\n",
    "    # Load the datasets\n",
    "    dataset_1 = pd.read_csv(file_path_1)\n",
    "    dataset_2 = pd.read_csv(file_path_2)\n",
    "    \n",
    "    # Concatenate the two DataFrames row-wise\n",
    "    combined_df = pd.concat([dataset_1, dataset_2], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Rename the first unnamed column to 'ID_1' if it exists\n",
    "    if 'Unnamed: 0' in combined_df.columns:\n",
    "        combined_df.rename(columns={'Unnamed: 0': 'ID_1'}, inplace=True)\n",
    "    \n",
    "    # Save to CSV if an output file path is provided\n",
    "    if output_file:\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595e8456-44bb-4303-96c2-027524965377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path_1 = \"/home/aghasemi/CompBio481/datasets/original_datasets/GSE120584_T.csv\"\n",
    "file_path_2 = \"/home/aghasemi/CompBio481/datasets/original_datasets/GSE167559_T.csv\"\n",
    "output_file = \"/home/aghasemi/CompBio481/datasets/processed_datasets/GSE120584_T_&_GSE167559_T_complete_dataset_without_clinical_factors.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76cf894-1d4d-4707-8739-857aa42992d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID_1  MIMAT0000062  MIMAT0000063  MIMAT0000064  MIMAT0000065  \\\n",
      "0  GSM3403761      2.307579      2.307579      2.307579      2.307579   \n",
      "1  GSM3403762      1.503044      2.505380      1.503044      1.503044   \n",
      "2  GSM3403763      1.549877      1.983125      1.549877      1.549877   \n",
      "3  GSM3403764      1.560269      1.560269      1.560269      1.560269   \n",
      "4  GSM3403765      3.179096      3.302472      3.179096      3.179096   \n",
      "\n",
      "   MIMAT0000066  MIMAT0000067  MIMAT0000068  MIMAT0000069  MIMAT0000070  ...  \\\n",
      "0      2.307579      2.307579      2.307579      2.307579      2.307579  ...   \n",
      "1      1.503044      1.503044      1.503044      1.503044      1.503044  ...   \n",
      "2      1.549877      1.549877      1.549877      1.549877      1.549877  ...   \n",
      "3      2.232974      1.560269      1.560269      1.560269      1.560269  ...   \n",
      "4      4.793470      3.179096      3.179096      3.179096      3.179096  ...   \n",
      "\n",
      "   MIMAT0031893  MIMAT0032026  MIMAT0032029  MIMAT0032110  \\\n",
      "0      2.307579      2.307579      8.224806      2.307579   \n",
      "1      1.503044      1.503044      7.921326      2.339842   \n",
      "2      1.549877      1.549877      7.659609      2.939463   \n",
      "3      1.560269      1.560269      7.145303      3.039567   \n",
      "4      3.179096      3.179096      8.254947      3.179096   \n",
      "\n",
      "   MIMAT0032114, MIMAT0032115  MIMAT0032116  MIMAT0033692  MIMAT0035542  \\\n",
      "0                    2.307579      4.838350      5.008100      4.013143   \n",
      "1                    1.503044      4.921429      5.103016      4.232799   \n",
      "2                    1.549877      5.448523      4.882961      3.991961   \n",
      "3                    1.560269      4.421061      4.522823      3.199755   \n",
      "4                    3.179096      4.437597      4.536771      3.730172   \n",
      "\n",
      "   MIMAT0035703  MIMAT0035704  \n",
      "0      2.307579      2.307579  \n",
      "1      1.503044      1.503044  \n",
      "2      1.549877      1.549877  \n",
      "3      1.560269      1.560269  \n",
      "4      3.179096      3.179096  \n",
      "\n",
      "[5 rows x 2563 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_dataset = concatenate_datasets(file_path_1, file_path_2, output_file)\n",
    "print(combined_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fa70a-141c-482d-8179-adc5b2912001",
   "metadata": {},
   "source": [
    "**Merge Main Dataset (GSE120584_T_&_GSE167559_T_complete_dataset_without_clinical_factors) with Clinical Factors**\n",
    "\n",
    "### Merge Main Dataset with Clinical Factors\n",
    "\n",
    "**Description:**\n",
    "\n",
    "- **Load the Datasets:** Reads the main dataset and clinical factors from CSV files.\n",
    "- **Rename Columns:** Updates column names in the clinical factors DataFrame.\n",
    "- **Merge DataFrames:** Combines the datasets on a common column.\n",
    "- **Apply Value Mapping:** Maps values in the specified column according to a given dictionary.\n",
    "- **Drop Column:** Removes a column if specified.\n",
    "- **Save to CSV:** Optionally saves the processed DataFrame to a new CSV file.\n",
    "- **Example Usage:** Merges the datasets, processes columns, and saves the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281591c5-67a1-434a-8d25-ccea137cc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a07d81f1-d7fd-44d1-8912-157e73cab9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_path = '/home/aghasemi/CompBio481/datasets/processed_datasets/GSE120584_T_&_GSE167559_T_complete_dataset_without_clinical_factors.csv'\n",
    "clinical_factors_file_path = '/home/aghasemi/CompBio481/datasets/processed_datasets/GSE120584_&_GSE167559_clinical_factors_combined.csv'\n",
    "output_file = '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/complete_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b80f34b1-8c24-44e5-a3d9-9b98fc5d434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_process_datasets(dataset_file_path, clinical_factors_file_path, common_column, rename_column_dict, value_map_column, value_map_dict, drop_column, output_file=None):\n",
    "    # Load the datasets\n",
    "    dataset = pd.read_csv(dataset_file_path)\n",
    "    clinical_factors = pd.read_csv(clinical_factors_file_path)\n",
    "    \n",
    "    # Rename the specified column in the clinical factors DataFrame\n",
    "    clinical_factors.rename(columns=rename_column_dict, inplace=True)\n",
    "    \n",
    "    # Merge the DataFrames on the common column\n",
    "    merged_df = pd.merge(dataset, clinical_factors, on=common_column, how='inner')\n",
    "    \n",
    "    # Rename columns according to the rename_column_dict including 'sex' to 'Sex'\n",
    "    merged_df.rename(columns=rename_column_dict, inplace=True)\n",
    "    \n",
    "    # Now 'Sex' is correctly capitalized, you can apply the value mapping\n",
    "    if value_map_column in merged_df.columns:\n",
    "        merged_df[value_map_column] = merged_df[value_map_column].map(value_map_dict)\n",
    "    \n",
    "    # Drop the specified column if needed\n",
    "    if drop_column in merged_df.columns:\n",
    "        merged_df = merged_df.drop(drop_column, axis=1)\n",
    "    \n",
    "    # Save to CSV if an output file path is provided\n",
    "    if output_file:\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0fcae4e-c083-4a4a-a073-229102b1b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = merge_and_process_datasets(\n",
    "    dataset_file_path=dataset_file_path,\n",
    "    clinical_factors_file_path=clinical_factors_file_path,\n",
    "    common_column='ID_1',\n",
    "    rename_column_dict={\n",
    "        'SampleID': 'ID_1',  # Rename 'SampleID' to 'ID_1'\n",
    "        'sex': 'Sex',  # Correctly rename 'sex' to 'Sex' before mapping\n",
    "        'age': 'Age',  # Capitalize 'age'\n",
    "        'apoe4': 'APOE4',  # Change 'apoe4' to 'APOE4'\n",
    "        'diagnosis': 'Diagnosis'  # Capitalize 'diagnosis'\n",
    "    },\n",
    "    value_map_column='Sex',  # Use the new capitalized 'Sex' column for mapping\n",
    "    value_map_dict={'female': 0, 'male': 1},\n",
    "    drop_column=None,  # No column is being dropped after processing\n",
    "    output_file=output_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb6fef-55ea-403c-8f8c-d6c0eb4376da",
   "metadata": {},
   "source": [
    "**Splitting Datasets into NC vs (disease groups)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5303d5ec-5cfa-4b7f-8528-a71d71704bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b31e9f4d-685e-41bf-b2d6-878c7d0efe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diagnosis_subdatasets(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    \n",
    "    # Get unique diagnosis values excluding 'NC'\n",
    "    unique_diagnoses = dataset['Diagnosis'].unique()\n",
    "    non_nc_diagnoses = [diagnosis for diagnosis in unique_diagnoses if diagnosis != 'NC']\n",
    "    \n",
    "    # Iterate over non-NC diagnoses to create subdatasets\n",
    "    for diagnosis in non_nc_diagnoses:\n",
    "        # Filter the dataset for 'NC' and the current non-NC diagnosis\n",
    "        filtered_dataset = dataset[dataset['Diagnosis'].isin(['NC', diagnosis])]\n",
    "        \n",
    "        # Save the filtered dataset to a CSV file\n",
    "        output_file = f'/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_{diagnosis}.csv'\n",
    "        filtered_dataset.to_csv(output_file, index=False)\n",
    "        print(f'Saved: {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99becd5b-5726-4e3f-92ee-b6fc366b8053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_AD.csv\n",
      "Saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_DLB.csv\n",
      "Saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_MCI.csv\n",
      "Saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_VaD.csv\n",
      "Saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_NPH.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = \"/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/complete_dataset.csv\"  # Update with the path to your complete dataset\n",
    "create_diagnosis_subdatasets(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29109f-1fff-4529-85aa-792f16e5516b",
   "metadata": {},
   "source": [
    "**Binarizing Diagnosis Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f46ece15-78bd-4346-a5d8-cbabd6a0d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f163bf07-a9ec-460b-b447-1d160da4deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_diagnosis(file_paths):\n",
    "    for file_path in file_paths:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Binarize the 'Diagnosis' column: 0 for 'NC', 1 for others\n",
    "        df['Diagnosis'] = df['Diagnosis'].apply(lambda x: 0 if x == 'NC' else 1)\n",
    "        \n",
    "        # Save the modified dataset back to its original file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Binarized and saved: {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d47ded9-946c-4f96-97aa-37eb688688fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file paths to your datasets\n",
    "file_paths = [\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_AD.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_DLB.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_MCI.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_VaD.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_NPH.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13293d63-df6e-4f20-a96a-212999f3d7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized and saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_AD.csv\n",
      "Binarized and saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_DLB.csv\n",
      "Binarized and saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_MCI.csv\n",
      "Binarized and saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_VaD.csv\n",
      "Binarized and saved: /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_NPH.csv\n"
     ]
    }
   ],
   "source": [
    "# Apply the binarization function to each dataset\n",
    "binarize_diagnosis(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070f880-9554-496c-8079-0db65134aac1",
   "metadata": {},
   "source": [
    "**Check for Duplicate Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b4b2b18-2060-4e65-bda1-55e95cf820a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ca5018b-327a-4bd8-9bf5-fd109e9eb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the files are stored\n",
    "directory_path = '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "951ee5f7-9511-4376-aec7-99b783c9348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for duplicate columns and rows in a dataframe\n",
    "def check_duplicates_in_dataframe(df):\n",
    "    # Check for duplicate columns\n",
    "    duplicate_columns = df.columns.duplicated()\n",
    "    # Check for duplicate rows\n",
    "    duplicate_rows = df.duplicated().any()\n",
    "    \n",
    "    return duplicate_columns, duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e9fe22a-5dc6-4a8b-ae25-4d75d708a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to keep track of the results for each file\n",
    "results = []\n",
    "\n",
    "# List the CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Iterate over the CSV files to check for duplicates\n",
    "for file_name in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(os.path.join(directory_path, file_name))\n",
    "    \n",
    "    # Check for duplicates in the DataFrame\n",
    "    duplicate_columns, duplicate_rows = check_duplicates_in_dataframe(df)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'file': file_name,\n",
    "        'duplicate_columns': duplicate_columns,\n",
    "        'duplicate_rows': duplicate_rows\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22bd723c-4315-4155-a51f-ca86df43f4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'NC_vs_MCI.csv',\n",
       "  'duplicate_columns': array([False, False, False, ..., False, False, False]),\n",
       "  'duplicate_rows': False},\n",
       " {'file': 'complete_dataset.csv',\n",
       "  'duplicate_columns': array([False, False, False, ..., False, False, False]),\n",
       "  'duplicate_rows': False},\n",
       " {'file': 'NC_vs_VaD.csv',\n",
       "  'duplicate_columns': array([False, False, False, ..., False, False, False]),\n",
       "  'duplicate_rows': False},\n",
       " {'file': 'NC_vs_AD.csv',\n",
       "  'duplicate_columns': array([False, False, False, ..., False, False, False]),\n",
       "  'duplicate_rows': False},\n",
       " {'file': 'NC_vs_NPH.csv',\n",
       "  'duplicate_columns': array([False, False, False, ..., False, False, False]),\n",
       "  'duplicate_rows': False},\n",
       " {'file': 'NC_vs_DLB.csv',\n",
       "  'duplicate_columns': array([False, False, False, ..., False, False, False]),\n",
       "  'duplicate_rows': False}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89ec66-1b47-493a-b9b7-7fdc6419cc18",
   "metadata": {},
   "source": [
    "**Train Test for Each Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d529e7dd-b3a0-4b84-a2d0-3455b80b0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0767c63-69d3-4613-9bb8-4b87b371cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_datasets(dataset_paths, save_directory, test_size=0.2, random_state=42):\n",
    "    for dataset_path in dataset_paths:\n",
    "        # Extract the base name for the dataset\n",
    "        base_name = os.path.basename(dataset_path).replace('.csv', '')\n",
    "        \n",
    "        # Load the dataset\n",
    "        dataset = pd.read_csv(dataset_path)\n",
    "        \n",
    "        # Perform the train-test split\n",
    "        train, test = train_test_split(dataset, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # Create the file names for the training and test sets\n",
    "        train_file_name = f\"{base_name}_train.csv\"\n",
    "        test_file_name = f\"{base_name}_test.csv\"\n",
    "        \n",
    "        # Construct the full paths for the new training and test set files\n",
    "        train_file_path = os.path.join(save_directory, train_file_name)\n",
    "        test_file_path = os.path.join(save_directory, test_file_name)\n",
    "        \n",
    "        # Save the training and test sets to their respective files\n",
    "        train.to_csv(train_file_path, index=False)\n",
    "        test.to_csv(test_file_path, index=False)\n",
    "        \n",
    "        print(f\"Train set saved to {train_file_path}\")\n",
    "        print(f\"Test set saved to {test_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1c46aba-6966-47d9-aef8-b34ecd724942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "file_paths = [\n",
    "    # List your file paths here\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_AD.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_DLB.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_MCI.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_NPH.csv',\n",
    "    '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch1/NC_vs_VaD.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d7b09db-82c1-4dd5-a5da-d26391980a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e691a4ab-3817-4221-bf6f-3156e2056492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_AD_train.csv\n",
      "Test set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_AD_test.csv\n",
      "Train set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_DLB_train.csv\n",
      "Test set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_DLB_test.csv\n",
      "Train set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_MCI_train.csv\n",
      "Test set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_MCI_test.csv\n",
      "Train set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_NPH_train.csv\n",
      "Test set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_NPH_test.csv\n",
      "Train set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_VaD_train.csv\n",
      "Test set saved to /home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch2/NC_vs_VaD_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Now call the function\n",
    "split_and_save_datasets(file_paths, save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73322016-2ad8-4950-b0d1-d25d5fce528d",
   "metadata": {},
   "source": [
    "**Multi_Label Dataset Construction Branch 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e409137-aa85-4f82-842d-7d908eb6d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a67909e2-98f7-488f-8e95-df40db41466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch3/complete_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de100ee8-5d23-4071-9320-eaf5341e53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39d945b2-1be6-4cb3-b518-204931943fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LabelEncoder to the 'Diagnosis' column and transform it\n",
    "dataset['Diagnosis'] = label_encoder.fit_transform(dataset['Diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7601a29-2dd5-40d9-ab93-4bb8527ef54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the transformed dataset and the unique classes with their corresponding labels\n",
    "transformed_head = dataset.head()\n",
    "unique_classes = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3f117d7-6d23-4d10-abc8-d076c827fcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         ID_1  MIMAT0000062  MIMAT0000063  MIMAT0000064  MIMAT0000065  \\\n",
       " 0  GSM3403761      2.307579      2.307579      2.307579      2.307579   \n",
       " 1  GSM3403762      1.503044      2.505380      1.503044      1.503044   \n",
       " 2  GSM3403763      1.549877      1.983125      1.549877      1.549877   \n",
       " 3  GSM3403764      1.560269      1.560269      1.560269      1.560269   \n",
       " 4  GSM3403765      3.179096      3.302472      3.179096      3.179096   \n",
       " \n",
       "    MIMAT0000066  MIMAT0000067  MIMAT0000068  MIMAT0000069  MIMAT0000070  ...  \\\n",
       " 0      2.307579      2.307579      2.307579      2.307579      2.307579  ...   \n",
       " 1      1.503044      1.503044      1.503044      1.503044      1.503044  ...   \n",
       " 2      1.549877      1.549877      1.549877      1.549877      1.549877  ...   \n",
       " 3      2.232974      1.560269      1.560269      1.560269      1.560269  ...   \n",
       " 4      4.793470      3.179096      3.179096      3.179096      3.179096  ...   \n",
       " \n",
       "    MIMAT0032114, MIMAT0032115  MIMAT0032116  MIMAT0033692  MIMAT0035542  \\\n",
       " 0                    2.307579      4.838350      5.008100      4.013143   \n",
       " 1                    1.503044      4.921429      5.103016      4.232799   \n",
       " 2                    1.549877      5.448523      4.882961      3.991961   \n",
       " 3                    1.560269      4.421061      4.522823      3.199755   \n",
       " 4                    3.179096      4.437597      4.536771      3.730172   \n",
       " \n",
       "    MIMAT0035703  MIMAT0035704  Diagnosis  Age  Sex  APOE4  \n",
       " 0      2.307579      2.307579          0   79    0      0  \n",
       " 1      1.503044      1.503044          0   77    0      1  \n",
       " 2      1.549877      1.549877          0   76    0      0  \n",
       " 3      1.560269      1.560269          0   88    0      1  \n",
       " 4      3.179096      3.179096          0   74    1      0  \n",
       " \n",
       " [5 rows x 2567 columns],\n",
       " array(['AD', 'DLB', 'MCI', 'NC', 'NPH', 'VaD'], dtype=object))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(transformed_head, unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "939b238d-b305-4bfb-969e-af97cc359425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"/home/aghasemi/CompBio481/datasets/processed_datasets/usable_datasets_branch3/multi_class_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
